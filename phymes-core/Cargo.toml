[package]
name = "phymes-core"
version = "0.1.0"
edition = "2024"

[features]
default = ["wsl","candle"]
wasip2 = ["tokenizers/unstable_wasm",
    "tokio/sync",
    "tokio/macros",
    "tokio/io-util",
    "tokio/rt"]
wsl = ["dep:tempfile",
    "tokenizers/onig",
    "tokio/full"]
wsl-gpu = ["wsl"]
candle = [] # force use of candle models when openai_api is available

[dependencies]
arrow = { version = "54.3.1", default-features = false, features = ["csv", "json", "ipc", "prettyprint"] }
pin-project-lite = "0.2.16"
async-trait = "0.1.88"
anyhow = "1.0.95"
futures = { version = "0.3.31", default-features = false, features = ["alloc"] }
tokio = { version = "1.45.1", default-features = false, features = [], optional = true}
tracing = "0.1.41"
tracing-subscriber = "0.3.19"
tracing-chrome = "0.7.2"
serde = { version = "1.0.217", features = ["derive"] }
serde_json = "1.0.135"
tempfile = { version = "3.20.0", optional = true }
parking_lot = "0.12.3"
web-time = "1.1.0"
hashbrown = "0.15.4"
chrono = { version = "0.4.41", features = ["wasmbind"] }
minijinja = { version = "2.11.0", features = ["json"] }
minijinja-contrib = { version = "2.6.0", features = ["pycompat"] }
candle-core = { git = "https://github.com/huggingface/candle.git", version = "0.9.1" }
tokenizers = { version = "0.21.1", default-features = false, optional = true }
bytes = "1.10.1"
getrandom = { version = "0.3.1", features = ["wasm_js"] }